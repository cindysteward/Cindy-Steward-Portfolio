{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cindysteward/Cindy-Steward-Portfolio/blob/main/ai_faces_and_datasets_generator.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Face Generation and Data Set Creation through Stable Diffusion**\n",
        "\n",
        "---\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "xdJVIGCDIo-x"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here I use Stable Diffusion v1.4 (a latent **text-to-image** diffusion model) to generate random images of faces through a **TTI** model, and transfer them into a numpy file, to create a dataset purposed for machine learning.\n",
        "\n",
        "The code is split into various sections for debugging and demonstration reasons."
      ],
      "metadata": {
        "id": "rp52RzUWIxv_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Initial Set-Up**"
      ],
      "metadata": {
        "id": "5RlZsIPJNaT0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Installing Huggingface and Diffusers\n",
        "#Installing the necessary libraries.\n",
        "!pip install huggingface_hub #login to huggingface to use Stable Diffusion.\n",
        "!pip install -qq diffusers[\"training\"]==0.3.0 transformers ftfy\n",
        "!pip install -qq \"ipywidgets>=7,<8\" #to login into huggingface, allows widget to show up in google colab\n",
        "!pip install diffusers==0.4.0 transformers scipy ftfy"
      ],
      "metadata": {
        "id": "kqX_0sxq3qkb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rucs3wKI2rok"
      },
      "outputs": [],
      "source": [
        "from huggingface_hub import notebook_login #enables us to use the huggingface repository.\n",
        "notebook_login()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Importing Libraries\n",
        "\n",
        "#import necessary libraries to use stable diffusion.\n",
        "#many different ones specifically, because my machine kept bugging when not having all.\n",
        "\n",
        "import os\n",
        "import random\n",
        "import cv2\n",
        "\n",
        "import numpy\n",
        "import torch\n",
        "\n",
        "import PIL\n",
        "from accelerate import Accelerator\n",
        "from diffusers import AutoencoderKL, DDPMScheduler, PNDMScheduler, StableDiffusionPipeline, UNet2DConditionModel\n",
        "from diffusers.pipelines.stable_diffusion import StableDiffusionSafetyChecker\n",
        "from PIL import Image\n",
        "from torchvision import transforms\n",
        "from tqdm.auto import tqdm\n",
        "from transformers import CLIPFeatureExtractor, CLIPTextModel, CLIPTokenizer"
      ],
      "metadata": {
        "id": "T7JkK1r_3Umb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#ensure and enable token, which allows access to the hugging face repository.\n",
        "YOUR_TOKEN=\"/root/.huggingface/token\""
      ],
      "metadata": {
        "id": "-VmJ-8WX4ULi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#set up the pipeline so we can inference the Stable Diffusion model.\n",
        "from diffusers import StableDiffusionPipeline"
      ],
      "metadata": {
        "id": "4XttFDmt36x_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Set up pipeline\n",
        "pipe = StableDiffusionPipeline.from_pretrained(\"CompVis/stable-diffusion-v1-4\", revision=\"fp16\", torch_dtype=torch.float16, use_auth_token=True)\n",
        "#since there may be limited GPU RAM available, load the pipeline in float16 precision, instead of the default 32 precision preset.\n",
        "\n",
        "#Move the pipeline to an available GPU. In google colab first change the runtime type,\n",
        "#and change the hardware accelerator to GPU. Then use CUDA to move it to a dedicated GPU.\n",
        "pipe.to(\"cuda\")"
      ],
      "metadata": {
        "id": "7OlsRXeEFML9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive') #allow google colab to access drive, so we can save files."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MrJpJjRMyQQK",
        "outputId": "253e3854-cb3f-4413-f2ef-8ab4c8713c78"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Generate Faces for Dataset**"
      ],
      "metadata": {
        "id": "N7QeavEZNQN-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Generate Images\n",
        "num_images = 3 #note the amount of images you want to generate from the dataset. This can be changed\n",
        "count = 0 #alternatively, the images could have been made in one single grid. However, we want to save the images seperately in a dataset.\n",
        "#the count variable is used to generate an image the amount of images requested. The while loop ensures this.\n",
        "prompt = \"a face on a passport photo\" #a prompt that defines what we went to generate.\n",
        "#In this case, I chose for passport photos, as people use deepfakes to identify as someone else, to deceive people or for example, trading or crypto platforms.\n",
        "while count < num_images:\n",
        "  image = pipe(prompt)[\"sample\"][0]\n",
        "  display(image) #let's display the image we generated!\n",
        "  count+=1 #we start with 0. when count is 2, 3 images have been generated.\n",
        "  image.save(f\"/content/face_data/face_passport_photo{count}.png\") #we save each image in the pre-existing face_data folder."
      ],
      "metadata": {
        "id": "3s--ix7e8okf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Data Set Creation**"
      ],
      "metadata": {
        "id": "mpxQLk6iqcBR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here I create the dataset through the use of a numpy file. I save the generated images in a list within a numpy file."
      ],
      "metadata": {
        "id": "vHDU3_qcL3Im"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "path = '/content/face_data' #define the path of where we want our dataset to be saved."
      ],
      "metadata": {
        "id": "uwTrNdr27ERf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "face_data = [] #create an empty file.\n",
        "for image in os.listdir(path):\n",
        "    pic = cv2.imread(os.path.join(path,image))\n",
        "    face_data.append([image]) #save each image as a list in the filepath we defined earlier using the cv2 module."
      ],
      "metadata": {
        "id": "qj_D3-taye-6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#converting the list to numpy array and saving it to a file\n",
        "numpy.save(os.path.join(path,'FacePassportDataSet.npy'),numpy.array(face_data))"
      ],
      "metadata": {
        "id": "i7CYpcJr7FG8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#here we load the numpy file to see the contents of the dataset\n",
        "numpy.load('/content/face_data/FacePassportDataSet.npy', mmap_mode=None, allow_pickle=True, fix_imports=True, encoding='ASCII')"
      ],
      "metadata": {
        "id": "uBqM09TJ7v4y"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}